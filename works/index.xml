<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Works on Kuniaki Shimizu</title>
    <link>https://kun432.github.io/works/</link>
    <description>Recent content in Works on Kuniaki Shimizu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-JP</language>
    <lastBuildDate>Sun, 28 Jul 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://kun432.github.io/works/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Alexaスキル「雨雲マップ」</title>
      <link>https://kun432.github.io/works/alexa-skill-raincloud-map/</link>
      <pubDate>Sun, 28 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kun432.github.io/works/alexa-skill-raincloud-map/</guid>
      <description>はじめに Alexaスキル「雨雲マップ」のページです。(2019/07/28申請中)
目次  はじめに 目次 使い方 実装について 今後の予定 更新履歴 プライバシーポリシー  本サービスが取得する利用者情報と利用目的 プライバシーポリシーの変更 お問い合わせ窓口   使い方 「アレクサ、雨雲を開いて」で起動します。初回起動時のみ、Alexaデバイスの住所情報を取得し、以降の利用ではその住所情報を元に、お住いの地域の雨雲レーダー画像を表示、現在および１時間後の雨の状況をお伝えします。ディスプレイ付きデバイス（Echo Spot/Echo Show）でのみ利用可能です。 実装について プロトタイプ作成後から少し時間が空いてしまいましたが、やっと完成させることができました。今回のテーマは「VoiceflowでAPIを活用したスキル」です。 同一の機能を持つスキルは他にも存在しますが、本スキルの優位性は以下の２点です。  最初に住所を登録しておけば、毎回いちいち住所を言わなくても良い 利用者ごとに異なるロケーションにあわせて最適化することにより、利用者の利便性を向上する  これまで作成してきたスキルでは、基本的にすべてのユーザに対して一律の機能を提供してきましたが、よりユーザごとにカスタマイズ性をもたせたスキル開発を行いたい、ということで、今回はAlexaの所在地情報APIを使ってみました。また、画面付きデバイス向けにマップ画像を使ったシンプルなスキルを作ってみたかったということもあり、Yahoo!JAPAN様が提供されているスタティックマップAPIと郵便番号APIと組み合わせて、  所在地情報APIで郵便番号取得 郵便番号APIで緯度経度取得 スタティックマップAPIで雨雲情報が付与されたマップ画像を取得  という形で、一度住所を登録しさえすれば、あとは起動するだけで最短で必要な雨雲情報を取り出せるというものになっています。 また、今回はスキル開発プラットフォームにVoiceflowを使っています。Voiceflowは以前から活用しており、実際に複数のシンプルなスキルをリリースしていますし、テスト的に凝ったこともやっていますが、今回は、複数の外部APIを叩いたり、アクセス権処理を追加したり、画面付きデバイス向けの画面対応など、かなりできることを盛り込んだ上で申請・公開する、というのをテーマにしていました。 ノンコーディングなのでかんたんだと思われがちですが（事実シンプルなものであればかんたんです）、実際には、設計書を作って、コードで同じことをやって、その上でVoiceflowで一度プロトタイプ組んで、と実は結構時間をかけています。というのも、この手のGUIツールは、かんたんにスタートができる反面、よく考えずに進めていくと、最終的にフローがぐちゃぐちゃになってしまい、非常にメンテがしづらいものになってしまう可能性が高いためです。こういった部分は外からは見えませんが、将来的な運用・保守コストを踏まえて、少し設計段階からきちんと考えてみました。 それでもコードを書くことに比べると、やはり保守の観点ではいろいろ課題は多い印象ですが、プロトタイピングやそれほど規模が大きくないものであれば、非常にスピーディーにスキルリリースまで進めれてしまう素晴らしいツールですし、このあたりで得られた知見を開発元やコミュニティに共有していくことで、Voiceflowがスキル開発初心者のみならずスキル開発経験者にも有用なツールとして日本でも普及し、Alexa開発者の裾野を広げれれば良いなと思ってます。 今後の予定  未定  更新履歴  v1.0(2019/07/28)  申請中   プライバシーポリシー kun432（以下，「私」といいます。）が提供するAlexaスキル「雨雲マップ」（以下、「本スキル」といいます。）および本スキルの利用により提供されるサービス（以下、本スキルの利用含め「本サービス」といいます。）をご利用いただく際に取得する「利用者情報」の取扱いについて，以下のとおりプライバシーポリシー（以下，「本ポリシー」といいます。）を定めます。  
本サービスが取得する利用者情報と利用目的  本サービスでは、Alexaアプリ・Echoデバイスに登録された利用者の「住所」のうち「郵便番号」を取得し、Yahoo! JAPANが提供する以下のAPI（以下、「外部API」といいます。）に対して、取得した「郵便番号」を送信することで、利用者のお住いの地域に基づいた気象情報の提供を行います。  
 「郵便番号検索API」  郵便番号から、お住いの地域の大まかな地名および緯度経度を取得します。  「Yahoo!スタティックマップAPI」および「気象情報API」  上記で取得した緯度経度から、お住いの地域の雨雲レーダー画像および降水強度情報を取得します。    本機能は、ご使用になられるAlexaアプリにて、利用者ご自身が本サービスに対して「住所」へのアクセスを許可する必要があります。これらに対して、利用者が許可しない限り、本サービスが「郵便番号」を取得することも、外部APIへ「郵便番号」を送信することもありません。また、郵便番号を元に取得した住所情報をスキル内に保存し、サービスの利用において住所情報を活用するかどうかを利用者に確認します。これに対して、利用者が同意しない限り、本サービスの利用を開始することはできません。本サービスの有効化、「住所」へのアクセス許可、ならびにスキルへの保存を許可することにより、利用者がこれらの情報の提供に同意したものとみなしますのでご留意ください。なお、これらの情報は、利用者に払い出されているユーザ識別子と紐付いていますが、スキルを無効化することによりユーザ識別子が変更されるため、取得した住所情報にアクセスすることはできなくなります。  また、取得した利用者情報は、本スキルの機能を提供するために一時的に利用するにとどまり、本ポリシーに記載されている場合を除き、第三者への提供を行うことはございません。</description>
    </item>
    
    <item>
      <title>大阪スマートスピーカーミーティング#7 LT 「Alexa Hostedおさらい＆Blueprintsでスキルリリースしてみた」</title>
      <link>https://kun432.github.io/works/osaka_smart_speaker_meeting_7_lt/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kun432.github.io/works/osaka_smart_speaker_meeting_7_lt/</guid>
      <description> はじめに 【大阪】スマートスピーカーミーティング 2019/02/28（https://osaka-driven-dev.connpass.com/event/117481/） のLTの資料と動画です。
資料 LT資料  動画（23:00〜50:40あたり）  内容 社外では初のLTです。Alexa HostedとAlexa Skill Blueprintsについて喋ってきました。
詳細は以下をご覧ください。 https://kun432.hatenablog.com/entry/smart_speaker_meeting_7_lt
参考  https://kun432.github.io/works/alexa-travel-japan-quiz/  </description>
    </item>
    
    <item>
      <title>Alexaスキル「Travel Japan Quiz」</title>
      <link>https://kun432.github.io/works/alexa-travel-japan-quiz/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kun432.github.io/works/alexa-travel-japan-quiz/</guid>
      <description>はじめに Alexaスキル「Travel Japan Quiz」のページです。
目次  はじめに 目次 使い方 実装について 今後の予定 更新履歴 プライバシーポリシー  使い方    注意！！！ amazon.comアカウントでないと利用できませんのでご注意ください 「Alexa、Open Travel Japan Quiz」で起動して、外国人に人気の日本の名所について、都道府県を当てるゲームです。 スキルを利用するには、 Amazonのスキルページ か Alexaダッシュボード から有効にして下さい。
実装について &amp;ldquo;Alexa Skill Blueprints&amp;rdquo; は、予め用意されているテンプレートをベースにプライベートなスキルを作ることができる公式サービスで、現時点ではUSのみ利用可能となっていますが、先日ストアへの申請が可能になったので、今後日本でも利用可能になることを踏まえて作ってみました。 詳細は以下にまとめてありますので、そちらもご覧ください。
 Alexa Skill Blueprintsでスキルを作って申請してみた（USのみ） - kun432&amp;rsquo;s blog Alexa Skill Blueprintsでスキルをリリースしてみた（USのみ） - kun432&amp;rsquo;s blog  技術的な要素は何もありませんが、こういったノンコーディングでスキルが作成できるサービスは現時点でもInvocable, Voiceflow, NOIDなどがあり、コードが書けなくても直感的に作れるサービスが増えてくることで、スキル開発者が増えることが期待できます。コードが書ける場合でも、コードを書くかノンコーディングツールを使うか、スキルの性質やスピード感なども踏まえて、どちらがよいか？を選択するようなシチュエーションが出てくると思います。今後も注目していきたいと思います。
今後の予定  クイズをもっと増やしていきたいです。  更新履歴  v1.0(2019/02/15)  公開   プライバシーポリシー このアプリケーションでは、ご利用になる皆様のいかなるプライバシー情報も収集、使用、共用することはありません。
2019月2月16日 制定
Kuniaki Shimizu</description>
    </item>
    
    <item>
      <title>Alexaスキル「１分間キャンドル」「１分間暖炉」「１分間サンセット」</title>
      <link>https://kun432.github.io/works/alexa-skill-1min-series/</link>
      <pubDate>Mon, 11 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kun432.github.io/works/alexa-skill-1min-series/</guid>
      <description>はじめに Alexaスキル「１分間キャンドル」「１分間暖炉」「１分間サンセット」のページです。
目次  はじめに 目次 使い方 実装について 今後の予定 更新履歴  「１分間キャンドル」 「１分間暖炉」 「１分間サンセット」  プライバシーポリシー  使い方 「アレクサ、１分間◯◯を開いて」で起動した後、「再生」と答えると、ランダムで１分程度の動画を再生します。ディスプレイ付きデバイス（Echo Spot/Echo Show）でのみ利用可能です。 実装について 2019年のスキル開発の個人的テーマとして、以下を設定しています。
 毎月、少なくとも１つのスキルをリリースする 毎月、少なくとも１つの新しいテーマに取り組む   1月のテーマは当初「セッション」を考えていたのですが、良いアイデアが思いつかず、急遽「動画再生」に変更しました。音楽や動画関連のスキルは非常に数が多くかつ人気も高いので、一度やってみたいと思っていましたが、実際にやってみると非常に簡単で、急遽ではありましたがやってみてよかったなと思います。簡単に実装できてしかも使ってもらいやすい、ということで、多数リリースされているのも納得です。動画コンテンツさえあれば比較的簡単に実装できるので、コード公開してますので、ぜひ皆さんもやっていただければと思います。 動画ファイルについて少し補足しておきます。 動画はすべてpixabayのロイヤリティフリー動画を使用しています。pixabayでは多数の動画素材を提供しているのですが、あくまでも素材ということもあり、ほとんどが1分未満のものです。当初は30分ぐらいの動画を再生したいと思っていたのですが、長時間のものはなかなか見つからない、あってもテーマに合わない、自分で作るのも手間、ということで、1分間未満を逆手にとって「仕事中などにちょっとした息抜きを」という目的に変えました。息抜き30分とか流石に怒られるでしょうし（笑）、よい落とし所だったのではないかなと思います。代りに複数の動画をランダムに再生するようにして、なるべく飽きすに継続して使ってもらえたらと思っています。 また、再生可能な動画ファイルのフォーマットは規定があるためffmpegで以下のような調整もしてます。
 職場等での利用を想定して無音化 1分に収まるよう再生部分の切り出し 4K非対応のため、動画の画面サイズの縮小 ストレージ容量・転送量削減のためのビットレートダウン  特に、ストレージ容量、転送量というところはコストにも帰ってくるため、「1分間」というところはこういうところでも意味があったりします。 実際には以降で述べるAlexa-hostedを利用しているため、ストレージ容量・転送量というところで追加コストが発生することはありませんが、逆に利用枠が決まっておりそれを超えるとスキルが使えなくなるため、このあたりのデータ量の削減は重要かなと思います。  
あと、今回のスキルでは、Alexa-hostedスキルで作成しました。これまでのスキル作成では、
 対話モデルはAlexa開発者コンソール バックエンドはAWS Lambda 動画等のファイルはAWS S3  と、複数のコンポーネントを使って管理画面を行ったり来たりするのが一般的だったのですが、Alexa-hosted（ただしベータ）を使うことにより、これらが全てAlexa開発者コンソールだけで完結するようになり、非常に開発がスムーズでした。大規模なスキル開発では厳しい面もあると思いますが、シンプルなものやプロトタイプ的なもの、個人での開発といったレベルだと十分ですね。今後も活用したいと思います。 コードはGithubで公開してます。 https://github.com/kun432/alexa-skill-1min-candle
https://github.com/kun432/alexa-skill-1min-fireplace
https://github.com/kun432/alexa-skill-1min-sunset
今後の予定  動画の再生制御については、今回は短い動画ということで単純な再生のみの実装となっていますが、実際には細かい制御が可能で、そのための標準インテントが多数用意されています。今後のバージョンアップ時にこれらに対応していきたいと思います。 動画は適宜追加予定です。  更新履歴 「１分間キャンドル」  v1.0(2019/01/30)  公開   「１分間暖炉」  v1.</description>
    </item>
    
    <item>
      <title>Alexaスキル「忠臣蔵こよみ」</title>
      <link>https://kun432.github.io/works/alexa-skill-chushingura-koyomi/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kun432.github.io/works/alexa-skill-chushingura-koyomi/</guid>
      <description> はじめに Alexaスキル「忠臣蔵こよみ」のページです。
目次  はじめに 目次 使い方 実装について 今後の予定 更新履歴 プライバシーポリシー  使い方    「アレクサ、忠臣蔵こよみを開いて」で起動して、その後、「知りたい」と答えると、忠臣蔵の討ち入り日である12月15日までの日数を数えてくれます。 実装について 今回のポイントは2点です。
 Echo Spotのような画面付きデバイス向けにDisplay Templateを使用し画像表示を行っています。また、画面付きデバイスの場合は、音声だけではなく、リストメニューを使ったタップによる入力も可能なので、これも実装してみました。 Alexaの声は、標準では女性の声なのですが、テーマに合わせて男性の声を使いたい、ということで、Amazon Pollyを使ってみました。SSMLだけで実装できるので非常に簡単です。あと、思いのほか、武士言葉でも普通に喋ってくれてびっくりしました（笑）  元々の音声のみのインタラクションは、これまでのGUIとは考え方が異なる難しさがありましたが、画面表示ができることにより視覚的に補完できる反面はあるものの、考慮すべきことも多くなり、違う意味での難しさもあるなと感じました。特に、
 シミュレータと実機で動きが違ったり、Echo Showの実機がなかったり、でテストが難しい。 画面付きの場合、セッションを明示的に切る必要があるが、挙動にばらつきがある。 複数のテンプレートが用意されており、かつ、同じテンプレートでもSpot/Showで見え方や画像処理が違う。  あたりはまだ手探り感があり、引き続きいろいろ試していく必要があると思っています。Echo Showも発売され、Fire TVもAlexa対応、さらにマルチモーダルな画面設計が行えるAPLなど、画面対応については非常に可能性があると思ってます。
あと、このスキル、討ち入り当日の12/15は時間ごとに討ち入りの模様が効果音付きで説明されます。今回最も苦労したのは、それを作るために、忠臣蔵の正確な時間推移を追うために書籍漁ったり、良さげで効果音を探すことだったり、します（笑） コードは、Alexa Skills Kit SDK for Node.jsのバージョン2で書いてます。バックエンドも定番の構成です。 コードはGithubで公開予定です。 https://github.com/kun432/alexa-skill-chushingura-koyomi
今後の予定  Clova/Google Home対応  更新履歴  v1.0 (2018/11/13)  公開   プライバシーポリシー このアプリケーションでは、ご利用になる皆様のいかなるプライバシー情報も収集、使用、共用することはありません。
2018年11月11日 制定
Kuniaki Shimizu
kun432.8d1w@gmail.com
 </description>
    </item>
    
    <item>
      <title>Alexaスキル「関ヶ原こよみ」「本能寺こよみ」</title>
      <link>https://kun432.github.io/works/alexa-skill-koyomi-series/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kun432.github.io/works/alexa-skill-koyomi-series/</guid>
      <description> はじめに Alexaスキル「関ヶ原こよみ」「本能寺こよみ」のページです。
目次  はじめに 目次 使い方 実装について 今後の予定 更新履歴 プライバシーポリシー  使い方 「アレクサ、〇〇こよみを開いて」で起動して、その後、「知りたい」と答えると、それぞれの出来事が起こった当日までの日数を数えてくれます。 実装について Alexaスキル開発キャンペーンに応募するために「忠臣蔵こよみ」を横展開しただけです。テーマを変えるだけでほぼ実装はいじっていません（多少当日の時間推移はいじっていますが）ので、これもまた、それぞれの歴史の書籍読んだり調べたりというのが工数の殆どを締めていたりします（笑） あと「忠臣蔵こよみ」でもそうなのですが、効果音いろいろと使っています。Amazonからも公式にAlexaサウンドライブラリが用意されており、SSMLで指定するだけで簡単に使えて、かつ、華やかになりますね。効果音はおすすめです。 コードは、Alexa Skills Kit SDK for Node.jsのバージョン2で書いてます。バックエンドも定番の構成です。コードはGithubで公開予定です。 https://github.com/kun432/alexa-skill-sekigahara-koyomi
https://github.com/kun432/alexa-skill-honnouji-koyomi
今後の予定  Clova/Google Home対応  更新履歴  関ヶ原こよみ v1.0 (2018/11/26)  公開  本能寺こよみ v1.0 (2018/11/26)  公開   プライバシーポリシー このアプリケーションでは、ご利用になる皆様のいかなるプライバシー情報も収集、使用、共用することはありません。
2018年11月26日 制定
Kuniaki Shimizu
kun432.8d1w@gmail.com
 </description>
    </item>
    
    <item>
      <title>Googleアクション「HTTPステータス検索」</title>
      <link>https://kun432.github.io/works/google-action-http-status-search/</link>
      <pubDate>Tue, 02 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kun432.github.io/works/google-action-http-status-search/</guid>
      <description> はじめに Actions on Googleアプリ「HTTPステータス検索」のページです。
目次  はじめに 目次 使い方 実装について 更新履歴 プライバシーポリシー  使い方    「OK, Google、HTTPステータス検索につないで」で起動し、その後、「ステータスコード200を教えて」というと、ステータスコードの意味を教えてくれます。 アクションの利用開始に、有効化等の作業は不要です。ぜひご利用ください。
実装について Alexa、Clovaに続いて、Google Home向けのアクションとして対応しました。基本的なロジックやVUI設計の考え方はそれほど変わりませんので、短期間で実装できましたが、以下のようなGoogle Home向けに特化した修正も行っています。
 インテントで受け取ったパラメータはWebhookでFirebase Functionsに渡していますが、Firebase Functions側で障害が発生した場合、Dialogflow側でテキストレスポンスを設定することで、利用者への障害通知を明確に伝えるようにしています。 SimpleResponseを使って、音声出力と画面出力を分けています。 また、画面出力が可能なデバイス向けに、サジェスチョンチップを表示し、会話のフォローを行えるようにしています。  また、これまでのAlexa, Clovaスキル開発時の経験を生かして以下のような改善も行っています・
 発話サンプル（Dialogflowでは、&amp;rdquo;Training phrases&amp;rdquo;）をエンティティに分解し、発話サンプルの登録数を減らしました。例えば、「ステータスコードXXXを調べて」「ステータスコードXXXを教えて」みたいな微妙な違いに関して、同士部分をエンティティ化することで、対応がやりやすくなります。 可能な限り、Dialogflow側だけで処理が完結できるようにして、どうしてもできない場合（受け取ったパラメータを処理する必要がある）にだけWebhookに渡すようにしました。これによりFirebase Functions側のコードは大幅にスッキリしました。  これで３大スマートスピーカー向けアプリ開発を一通り経験できましたので、今後はそれぞれのスピーカーおよびクラウドの特性を活かした機能の活用を進めていきたいと考えています。 コードはGithubで公開予定です。 https://github.com/kun432/google-action-http-status-code
更新履歴  v1.0(2018/10/4)  公開   プライバシーポリシー このアプリケーションでは、ご利用になる皆様のいかなるプライバシー情報も収集、使用、共用することはありません。
2018月10月2日 制定
Kuniaki Shimizu
kun432.8d1w@gmail.com
 </description>
    </item>
    
    <item>
      <title>Clovaスキル「HTTPステータス検索」</title>
      <link>https://kun432.github.io/works/clova-skill-http-status-search/</link>
      <pubDate>Mon, 24 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kun432.github.io/works/clova-skill-http-status-search/</guid>
      <description> はじめに Clovaスキル「HTTPステータス検索」のページです。
目次  はじめに 目次 使い方 実装について 更新履歴 プライバシーポリシー  使い方    「ねぇClova、HTTPステータス検索を開いて」で起動し、その後、「ステータスコード200を教えて」というと、ステータスコードの意味を教えてくれます。 スキルを利用するには、 Clovaアプリから有効にしてください。
実装について CEKのExtension Serverは、公式のハンズオン等ではHerokuが使用されていますが、
 HerokuのDynoは一定期間アクセスがなければ停止する。再アクセスすれば起動するが、起き上がるのに時間がかかる。 一般的には外から定期的に叩くことで回避するようだが、アクセスがそれほどないのにずっと起動している必要性もなければ、そのためにわざわざ別の機構を用意するのはナンセンス。 必要なときだけ、瞬時に上がるLambdaがベター。 ただし、CEKから直接Lambdaは叩けないので、API Gatewayを経由。  ということで、AWS API GatewayとAWS Lambdaを使用しています。 また、LambdaのエイリアスとAPI Gatewayのステージを使ったバージョン管理にも対応しています。Code Pipelineを使うともっと楽に管理できるようなので、次回への課題とします。 コードは、CEK SDK for Node.jsを使用しています。AlexaとClovaで日本語の認識に差があったり、スロットのエラー処理がやや異なる、などの差異があったもの、比較的ライトに対応でき、Alexaスキル「HTTPステータスコード」から流用できた部分が多かったこと、ClovaにおけるLambda実装例も揃ってきたこともあり、全体的には短期間で実装できました。 コードはGithubで公開してます。 https://github.com/kun432/clova-skill-http-status-code
更新履歴  v1.0(2018/9/25)  公開   プライバシーポリシー このアプリケーションでは、ご利用になる皆様のいかなるプライバシー情報も収集、使用、共用することはありません。
2018月9月24日 制定
Kuniaki Shimizu
kun432.8d1w@gmail.com
 </description>
    </item>
    
    <item>
      <title>Alexaスキル「HTTPステータス検索」</title>
      <link>https://kun432.github.io/works/alexa-skill-http-status-search/</link>
      <pubDate>Mon, 17 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kun432.github.io/works/alexa-skill-http-status-search/</guid>
      <description> はじめに Alexaスキル「HTTPステータス検索」のページです。
目次  はじめに 目次 使い方 実装について 今後の予定 更新履歴 プライバシーポリシー  使い方    「アレクサ、HTTPステータス検索を開いて」で起動し、その後、「ステータスコード200を教えて」というと、ステータスコードの意味を教えてくれます。 「アレクサ、HTTPステータス検索を開いて200を教えて」と一気に指定することもできます。 スキルを利用するには、 Amazonのスキルページ か Alexaダッシュボード から有効にして下さい。
実装について 初のAlexaスキルということで、まずはシンプルに「辞書的」なスキルを作ってみました。「任意のキーワードからデータを引っ張ってくる」というのは、Alexaにおけるデータの流れを理解しやすく、かつ、汎用性が高い（データを置き換えるだけでいろいろ応用が効く）パターンだと思うので、最初のテーマとしてはとても良かったと思います。 コードは、Alexa Skills Kit SDK for Node.jsのバージョン2で書いてます。シンプルなスキルですが、以下のような工夫も入れてます。
 ちょうどv2が発表された後で情報もあまりなかったのですが、今後v1→v2になっていくことを考えて、情報収集しつつ実装してみました。 各HTTPステータスコードの説明は、Wikipediaの&amp;rdquo;HTTPステータスコード&amp;rdquo;の説明を元に発話を作っていますが、発話に英語文字列が含まれている（例：101 Switching Protocols）場合、Alexaの読み上げで正しく発音してくれるものとそうでないものがあったりします。そのため、意図的にレスポンスに渡す文字列に含まれる英語文字列をカタカナ英語にするなどの調整をしています。 上記に関連して、スマートフォンのAlexaアプリには「カード」機能があり、スキルからのレスポンスを文字列で表示してくれます。一般的な実装では、発話も表示も同じテキストを渡すことが多いようですが、カードに渡す文字列はSSMLを認識せずそのまま表示されるため、発話を調整している場合は発話と表示を分けて管理する必要があります。本スキルではSSMLを使っていないものの、カタカナ表記がそのまま表示されるため、これに対応しています。 結論としては、発話と表示は分けて管理する、発話の調整はSSMLを使う、というのがよいということですね。Echo Spotのようなディスプレイ付モデルも出てきたため、今後のノウハウとしたいと思います。  バックエンドも、シンプルにAlexaの一般的かつミニマムな構成としてLambdaのみです。サーバーレスはこれまで使ったことが全くなかったのですが、必要な時だけ瞬時にあがる効率性はスマートスピーカーのユースケースにぴったりですね。Lambdaのバージョン管理や自動化というところは改善の余地がありますので、今後の課題とします。 コードはGithubで公開予定です。 https://github.com/kun432/alexa-skill-http-status-code
今後の予定  Echo Spot対応 Clova/Google Home対応  ※Clova版はこちら
更新履歴  v1.0 (2018/9/13)  公開   プライバシーポリシー このアプリケーションでは、ご利用になる皆様のいかなるプライバシー情報も収集、使用、共用することはありません。
2018年9月13日 制定
Kuniaki Shimizu
kun432.8d1w@gmail.com
 </description>
    </item>
    
  </channel>
</rss>